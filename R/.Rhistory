# Table
p3 <- DD %>% ggplot()+
# geom_errorbarh(aes(xmin=lowerCI95,xmax=upperCI95,y=rowname) ) +
# geom_point(aes(x=median,y=rowname)) +
geom_text(aes(x=.85,label=(tag), y=rowname),size=3) +
#xlim(-.25,1) +
theme_void() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank(),
)
p <- (p2 + p3)
return(list(s,p))
}
# Set up R environment options.
knitr::opts_chunk$set(echo = TRUE)
# Load cleaned data
load(file = "Data.RData")
# non-calibrated models 0M
# Define non-calibrated models 0M
form0M_procustus <- bf(response0M_procustus ~ 0 + condition  +  (1 | condition:participant) + (1|condition:trial) )
form0M_sparc <- bf(response0M_sparc         ~ 0 + condition  +  (1 | condition:participant) + (1|condition:trial) )
form0M_procustus_d <- bf(response0M_procustus ~ 0 + condition  * difficulty_s + (1 + difficulty_s | condition:participant) + (1|condition:trial) )
form0M_sparc_d <- bf(response0M_sparc         ~ 0 + condition  *  difficulty_s + (1 + difficulty_s| condition:participant) + (1|condition:trial) )
# Define priors
#prior0M <- get_prior( form0M_procustus , data = Data)
prior0M <- c(brms::prior(normal(0.5, .25), class = "b"))
# Run models
model_procustus0M <- run_model_cmdstanr(Data,form0M_procustus,"skew_normal",prior0M)
prior0M <- c(brms::prior(normal(10, .25), class = "b"))
model_sparc0M <- run_model_cmdstanr(Data,form0M_sparc,"skew_normal",prior0M)
prior0M_d <- c(brms::prior(normal(0.5, .25), class = "b"))
model_procustus0M_d <- run_model_cmdstanr(Data,form0M_procustus_d,"skew_normal",prior0M_d)
prior0M_d <- c(brms::prior(normal(10, .25), class = "b"))
model_sparc0M_d <- run_model_cmdstanr(Data,form0M_sparc_d,"skew_normal",prior0M_d)
# Save models
save(file = "Fit/model_procustus0M.RData", model_procustus0M)
save(file = "Fit/model_sparc0M.RData", model_sparc0M)
save(file = "Fit/model_procustus0M_d.RData", model_procustus0M_d)
save(file = "Fit/model_sparc0M_d.RData", model_sparc0M_d)
# Load data
load(file = "Data.RData")
# Define calibrated models 1M
form1M_procustus <- bf(response1M_procustus ~ 0 + condition  +  (1 | condition:participant) + (1|condition:trial) )
form1M_sparc <- bf(response1M_sparc         ~ 0 + condition  +  (1 | condition:participant) + (1|condition:trial) )
form1M_procustus_d <- bf(response1M_procustus ~ 0 + condition  * difficulty_s + (1 + difficulty_s | condition:participant) + (1|condition:trial) )
form1M_sparc_d <- bf(response1M_sparc         ~ 0 + condition  *  difficulty_s + (1 + difficulty_s| condition:participant) + (1|condition:trial) )
# Define priors
#prior0M <- get_prior( form0M_procustus , data = Data)
prior1M <- c(brms::prior(normal(0.5, .25), class = "b"))
# Run models
model_procustus1M <- run_model_cmdstanr(Data,form1M_procustus,"skew_normal",prior1M)
prior1M <- c(brms::prior(normal(0.5, .25), class = "b"))
model_sparc1M <- run_model_cmdstanr(Data,form1M_sparc,"skew_normal",prior1M)
prior1M_d <- c(brms::prior(normal(0.5, .25), class = "b"))
model_procustus1M_d <- run_model_cmdstanr(Data,form1M_procustus_d,"skew_normal",prior1M_d)
prior1M_d <- c(brms::prior(normal(10, .25), class = "b"))
model_sparc1M_d <- run_model_cmdstanr(Data,form1M_sparc_d,"skew_normal",prior1M_d)
# Save models
save(file = "Fit/model_procustus1M.RData", model_procustus1M)
save(file = "Fit/model_sparc1M.RData", model_sparc1M)
save(file = "Fit/model_procustus1M_d.RData", model_procustus1M_d)
save(file = "Fit/model_sparc1M_d.RData", model_sparc1M_d)
# Load data
load("Data.RData")
# Define priors
prior0 <- c(brms::prior(normal(0, 3), class = "b"))
prior0M <- c(brms::prior(normal(0, 3), class = "b"),
brms::prior(normal(0, 3), class = "b", coef = "log_response0M_procustus"))
prior1M <- c(brms::prior(normal(0, 3), class = "b"),
brms::prior(normal(0, 3), class = "b", coef = "response1M_procustus"))
# Define models for Questionnaires
formH3 <-  bf(WPQ ~ 0 + condition   + (1  |  condition:participant + condition:trial) )
formH3response0M_procustus <- bf(WPQ ~ 0 + log_response0M_procustus * condition   +  (1  |  condition:participant + condition:trial))
formH3response1M_procustus <- bf(WPQ ~ 0 + response1M_procustus * condition   +  (1  |  condition:participant + condition:trial) )
# Run models
modelH3_WPQ <- run_model_cmdstanr(Data,formH3,"gaussian",prior0)
modelH3response0M_WPQ <- run_model_cmdstanr(Data,formH3response0M_procustus,"gaussian",prior0M )
modelH3response1M_WPQ <- run_model_cmdstanr(Data,formH3response1M_procustus,"gaussian",prior1M )
# Define models for Questionnaires
formH3 <-  bf(MPQS ~ 0 + condition   + (1  |  condition:participant + condition:trial) )
formH3response0M_procustus <- bf(MPQS ~ 0 + log_response0M_procustus * condition +  (1  |  condition:participant + condition:trial))
formH3response1M_procustus <- bf(MPQS ~ 0 + response1M_procustus * condition +  (1  |  condition:participant + condition:trial) )
# Run models
modelH3_MPQS <- run_model_cmdstanr(Data,formH3,"gaussian",prior0)
modelH3response0M_MPQS <- run_model_cmdstanr(Data,formH3response0M_procustus,"gaussian",prior0M )
modelH3response1M_MPQS <- run_model_cmdstanr(Data,formH3response1M_procustus,"gaussian",prior1M )
# Define models for Questionnaires
formH3 <-  bf(MPQP ~ 0 + condition   + (1  |  condition:participant + condition:trial) )
formH3response0M_procustus <- bf(MPQP ~ 0 + log_response0M_procustus * condition  +   (1  |  condition:participant + condition:trial))
formH3response1M_procustus <- bf(MPQP ~ 0 + response1M_procustus * condition  +   (1  |  condition:participant + condition:trial) )
# Run models
modelH3_MPQP <- run_model_cmdstanr(Data,formH3,"gaussian",prior0)
modelH3response0M_MPQP <- run_model_cmdstanr(Data,formH3response0M_procustus,"gaussian",prior0M )
modelH3response1M_MPQP <- run_model_cmdstanr(Data,formH3response1M_procustus,"gaussian",prior1M )
# Define models for Questionnaires
formH3 <-  bf(Difficulty ~ 0 + condition + (1  |  condition:participant + condition:trial) )
formH3response0M_procustus <- bf(difficulty_s ~ 0 + log_response0M_procustus * condition  +  (1  |  condition:participant + condition:trial))
formH3response1M_procustus <- bf(difficulty_s ~ 0 + response1M_procustus * condition +  (1  |  condition:participant + condition:trial) )
# Run models
modelH3_Difficulty <- run_model_cmdstanr(Data,formH3,"gaussian",prior0)
modelH3response0M_Difficulty <- run_model_cmdstanr(Data,formH3response0M_procustus,"gaussian",prior0M )
modelH3response1M_Difficulty <- run_model_cmdstanr(Data,formH3response1M_procustus,"gaussian",prior1M )
# Save models
save(file = "Fit/modelH3_WPQ.RData",modelH3_WPQ)
save(file = "Fit/modelH3response0M_WPQ.RData",modelH3response0M_WPQ)
save(file = "Fit/modelH3response1M_WPQ.RData",modelH3response1M_WPQ)
save(file = "Fit/modelH3_MPQS.RData",modelH3_MPQS)
save(file = "Fit/modelH3response0M_MPQS.RData",modelH3response0M_MPQS)
save(file = "Fit/modelH3response1M_MPQS.RData",modelH3response1M_MPQS)
save(file = "Fit/modelH3_MPQP.RData",modelH3_MPQP)
save(file = "Fit/modelH3response0M_MPQP.RData",modelH3response0M_MPQP)
save(file = "Fit/modelH3response1M_MPQP.RData",modelH3response1M_MPQP)
save(file = "Fit/modelH3_Difficulty.RData",modelH3_Difficulty)
save(file = "Fit/modelH3response0M_Difficulty.RData",modelH3response0M_Difficulty)
save(file = "Fit/modelH3response1M_Difficulty.RData",modelH3response1M_Difficulty)
knitr::opts_chunk$set(echo = TRUE)
# Load non-calibrated Procustus and Sparc models
load(file = "Fit/model_procustus0M.RData")
load(file = "Fit/model_procustus0M_d.RData")
load(file = "Fit/model_sparc0M.RData")
load(file = "Fit/model_sparc0M_d.RData")
# Bayesian model comparison, post-analysis, and hypothesis testing for Procustus
BF_model_comparison_procustus0M <- do_BF_comparison(model_procustus0M,model_procustus0M_d)
post_analysis_procustus0M <- do_post_analysis(model_procustus0M)
hypothesis_test_procustus0M <- do_hypothesis_test(model_procustus0M)
# Bayesian model comparison, post-analysis, and hypothesis testing for Sparc
BF_model_comparison_sparc0M <- do_BF_comparison(model_sparc0M,model_sparc0M_d)
post_analysis_sparc0M <- do_post_analysis(model_sparc0M)
hypothesis_test_sparc0M <- do_hypothesis_test(model_sparc0M)
# Save results
save(file = "Results/BF_model_comparison_procustus0M.RData", BF_model_comparison_procustus0M)
save(file = "Results/post_analysis_procustus0M.RData", post_analysis_procustus0M)
save(file = "Results/hypothesis_test_procustus0M.RData", hypothesis_test_procustus0M)
save(file = "Results/BF_model_comparison_sparc0M.RData", BF_model_comparison_sparc0M)
save(file = "Results/post_analysis_sparc0M.RData", post_analysis_sparc0M)
save(file = "Results/hypothesis_test_sparc0M.RData", hypothesis_test_sparc0M)
# Load calibrated Procustus and Sparc models
load(file = "Fit/model_procustus1M.RData")
load(file = "Fit/model_procustus1M_d.RData")
load(file = "Fit/model_sparc1M.RData")
load(file = "Fit/model_sparc1M_d.RData")
# Bayesian model comparison, post-analysis, and hypothesis testing for Procustus
BF_model_comparison_procustus1M <- do_BF_comparison(model_procustus1M,model_procustus1M_d)
post_analysis_procustus1M <- do_post_analysis(model_procustus1M)
hypothesis_test_procustus1M <- do_hypothesis_test(model_procustus1M)
# Bayesian model comparison, post-analysis, and hypothesis testing for Sparc
BF_model_comparison_sparc1M <- do_BF_comparison(model_sparc1M,model_sparc1M_d)
post_analysis_sparc1M <- do_post_analysis(model_sparc1M)
hypothesis_test_sparc1M <- do_hypothesis_test(model_sparc1M)
# Save results
save(file = "Results/BF_model_comparison_procustus1M.RData", BF_model_comparison_procustus1M)
save(file = "Results/post_analysis_procustus1M.RData", post_analysis_procustus1M)
save(file = "Results/hypothesis_test_procustus1M.RData", hypothesis_test_procustus1M)
save(file = "Results/BF_model_comparison_sparc1M.RData", BF_model_comparison_sparc1M)
save(file = "Results/post_analysis_sparc1M.RData", post_analysis_sparc1M)
save(file = "Results/hypothesis_test_sparc1M.RData", hypothesis_test_sparc1M)
# Load calibrated Procustus model
load(file = "Fit/model_procustus1M.RData")
fit <- model_procustus1M
# Extract and manipulate posterior samples for trial distributions
sd <- fit %>% spread_draws(`r_condition:trial`[A,Intercept],`b_condition1`,`b_condition2`)
sd_11 <- sd %>% filter(A == c("1_1")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_1", c = "1", t = "1" )
sd_12 <- sd %>% filter(A == c("1_2")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_2", c = "1", t = "2" )
sd_13 <- sd %>% filter(A == c("1_3")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_3", c = "1", t = "3" )
sd_14 <- sd %>% filter(A == c("1_4")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_4", c = "1", t = "4" )
sd_21 <- sd %>% filter(A == c("2_1")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_1", c = "2", t = "1" )
sd_22 <- sd %>% filter(A == c("2_2")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_2", c = "2", t = "2" )
sd_23 <- sd %>% filter(A == c("2_3")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_3", c = "2", t = "3" )
sd_24 <- sd %>% filter(A == c("2_4")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_4", c = "2", t = "4" )
# Combine results for visualization
sd_ct <- rbind(sd_11, sd_12, sd_13, sd_14, sd_21, sd_22, sd_23, sd_24)
# Create a plot for Procustus trial distributions
p1 <- sd_ct %>%
ggplot(aes(x= t, y = ct_values, color = c)) +
stat_pointinterval(.width = c(.5,.95), position = position_dodge(width = 0.2)) +
theme_bw() +
xlab("trial") +
ylab("Post. distr. (ci-50/95%) of condition and trials") +
ggtitle("Procustus calibrated")
# Save the plot
make_fig("FiguresPaper/ConditionTrialsPostDistr_Procustus1M",p1)
# Load calibrated Sparc model
load(file = "Fit/model_sparc1M.RData")
fit <- model_sparc1M
# Extract and manipulate posterior samples for trial distributions (similar to Procustus)
sd <- fit %>% spread_draws(`r_condition:trial`[A,Intercept],`b_condition1`,`b_condition2`)
sd_11 <- sd %>% filter(A == c("1_1")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_1", c = "1", t = "1" )
sd_12 <- sd %>% filter(A == c("1_2")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_2", c = "1", t = "2" )
sd_13 <- sd %>% filter(A == c("1_3")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_3", c = "1", t = "3" )
sd_14 <- sd %>% filter(A == c("1_4")) %>% mutate(ct_values = `r_condition:trial` + `b_condition1`, ct_names = "1_4", c = "1", t = "4" )
sd_21 <- sd %>% filter(A == c("2_1")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_1", c = "2", t = "1" )
sd_22 <- sd %>% filter(A == c("2_2")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_2", c = "2", t = "2" )
sd_23 <- sd %>% filter(A == c("2_3")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_3", c = "2", t = "3" )
sd_24 <- sd %>% filter(A == c("2_4")) %>% mutate(ct_values = `r_condition:trial` + `b_condition2`, ct_names = "2_4", c = "2", t = "4" )
# Combine results for visualization
sd_ct <- rbind(sd_11, sd_12, sd_13, sd_14, sd_21, sd_22, sd_23, sd_24)
# Create a plot for Sparc trial distributions
p1 <- sd_ct %>%
ggplot(aes(x= t, y = ct_values, color = c)) +
stat_pointinterval(.width = c(.5,.95), position = position_dodge(width = 0.2)) +
theme_bw() +
xlab("trial") +
ylab("Post. distr. (ci-50/95%) of condition and trials") +
ggtitle("Sparc calibrated")
# Save the plot
make_fig("FiguresPaper/ConditionTrialsPostDistr_Sparc1M",p1)
# Load non-calibrated questionnaire models
load(file = "Fit/modelH3_WPQ.RData")
load(file = "Fit/modelH3response0M_WPQ.RData")
load(file = "Fit/modelH3response1M_WPQ.RData")
load(file = "Fit/modelH3_MPQS.RData")
load(file = "Fit/modelH3response0M_MPQS.RData")
load(file = "Fit/modelH3response1M_MPQS.RData")
load(file = "Fit/modelH3_MPQP.RData")
load(file = "Fit/modelH3response0M_MPQP.RData")
load(file = "Fit/modelH3response1M_MPQP.RData")
load(file = "Fit/modelH3_Difficulty.RData")
load(file = "Fit/modelH3response0M_Difficulty.RData")
load(file = "Fit/modelH3response1M_Difficulty.RData")
# Bayesian model comparison for each questionnaire
BF_model_comparison_WPQ_0M <- do_BF_comparison(modelH3_WPQ,modelH3response0M_WPQ)
BF_model_comparison_MPQS_0M <- do_BF_comparison(modelH3_MPQS,modelH3response0M_MPQS)
BF_model_comparison_MPQP_0M <- do_BF_comparison(modelH3_MPQP,modelH3response0M_MPQP)
BF_model_comparison_Difficulty_0M <- do_BF_comparison(modelH3_Difficulty,modelH3response0M_Difficulty)
BF_model_comparison_WPQ_1M <- do_BF_comparison(modelH3_WPQ,modelH3response1M_WPQ)
BF_model_comparison_MPQS_1M <- do_BF_comparison(modelH3_MPQS,modelH3response1M_MPQS)
BF_model_comparison_MPQP_1M <- do_BF_comparison(modelH3_MPQP,modelH3response1M_MPQP)
BF_model_comparison_Difficulty_1M <- do_BF_comparison(modelH3_Difficulty,modelH3response1M_Difficulty)
# Basic diagnostics for each questionnaire
post_analysis_procustus_basicWPQ <- do_post_analysis(modelH3_WPQ) #basic model
post_analysis_procustus_basicMPQS <- do_post_analysis(modelH3_MPQS) #basic model
post_analysis_procustus_basicMPQP <- do_post_analysis(modelH3_MPQP) #basic model
post_analysis_procustus_basicDifficulty <- do_post_analysis(modelH3_Difficulty) #basic model
# Contrasts for each questionnaire
Contrast_WPQ <- do_hypothesis_test(modelH3_WPQ)
Contrast_MPQS <- do_hypothesis_test(modelH3_MPQS)
Contrast_WPQP <- do_hypothesis_test(modelH3_MPQP)
Contrast_Difficulty <- do_hypothesis_test(modelH3_Difficulty)
save(file = "Results/Contrast_WPQ.RData", Contrast_WPQ)
save(file = "Results/Contrast_MPQS.RData", Contrast_MPQS)
save(file = "Results/Contrast_MPQP.RData", Contrast_WPQP)
save(file = "Results/Contrast_Difficulty.RData", Contrast_Difficulty)
# Save results
save(file = "Results/BF_model_comparison_WPQ_0M.RData", BF_model_comparison_WPQ_0M)
save(file = "Results/BF_model_comparison_MPQS_0M.RData", BF_model_comparison_MPQS_0M)
save(file = "Results/BF_model_comparison_MPQP_0M.RData", BF_model_comparison_MPQP_0M)
save(file = "Results/BF_model_comparison_Difficulty_0M.RData", BF_model_comparison_Difficulty_0M)
save(file = "Results/BF_model_comparison_WPQ_1M.RData", BF_model_comparison_WPQ_1M)
save(file = "Results/BF_model_comparison_MPQS_1M.RData", BF_model_comparison_MPQS_1M)
save(file = "Results/BF_model_comparison_MPQP_1M.RData", BF_model_comparison_MPQP_1M)
save(file = "Results/BF_model_comparison_Difficulty_1M.RData", BF_model_comparison_Difficulty_1M)
save(file = "Results/post_analysis_procustus_basicWPQ.RData", post_analysis_procustus_basicWPQ)
save(file = "Results/post_analysis_procustus_basicMPQS.RData", post_analysis_procustus_basicMPQS)
save(file = "Results/post_analysis_procustus_basicMPQP.RData", post_analysis_procustus_basicMPQP)
save(file = "Results/post_analysis_procustus_basicDifficulty.RData", post_analysis_procustus_basicDifficulty)
# Load results for non-calibrated models
load(file = "Results/post_analysis_procustus_basicWPQ.RData")
load(file = "Results/post_analysis_procustus_basicMPQS.RData")
load(file = "Results/post_analysis_procustus_basicMPQP.RData")
# Display results for basicWPQ
post_analysis_procustus_basicWPQ
# Display results for basicMPQS
post_analysis_procustus_basicMPQS
# Display results for basicMPQP
post_analysis_procustus_basicMPQP
# Display results for basicMPQS
post_analysis_procustus_basicMPQS
# Display results for basicMPQP
post_analysis_procustus_basicMPQP
knitr::opts_chunk$set(echo = TRUE)
# Analyze and visualize simulation results
Res0 <- Score %>% filter(!(nParti_loop == 11)) %>% group_by(nParti_loop,sdParti_loop,mDiff_loop) %>% summarize(s = mean(score))
knitr::opts_chunk$set(echo = TRUE)
# Initialize Score dataframe
Score <- data.frame()
#Parti <- data.frame()
# Specify parameters for power analysis
nParti <- c(5, 10, 11, 15, 20, 25, 30) # number participants
sdParti <- c(0.25) # sd participants
mDiff <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5) # for calculatingCohen's d
# 1. Initialize - Create a simulated dataset and fit a Bayesian model
n_condition = 2
n_participant = 11
n_trial = 4
sd_participant = .25
total = n_condition * n_participant * n_trial
condition1 <- rnorm(total/2,0.2,1) %>% data.frame(condition.value = .)
condition2 <- rnorm(total/2,0,1) %>% data.frame(condition.value = .)
condition <- rbind(condition1,condition2)
cohend = 0.2 /sd(condition$condition.value)
print(paste("cohend",cohend))
# dit kan beter door elke participant ook conditioneel te maken tov conditie
participant <- rnorm(total,0,sd_participant) %>% data.frame(participant.value = .)
trial <- rnorm(total,0,0.1 ) %>% data.frame(trial.value = .)
gr_value <- cbind(condition,participant,trial) %>% data.frame()
gr_name <- expand_grid(c("c1","c2"),factor(c(1:n_participant)),factor(c(1:n_trial)))  %>% data.frame()
names(gr_name) <- c("condition.name","participant.name","trial.name")
gr <- cbind(gr_value,gr_name)
sim_dataset <- gr %>% mutate(response = condition.value + participant.value + trial.value)
sim_dataset <- sim_dataset %>% mutate(condition.name = factor(condition.name),
participant.name = factor(participant.name),
trial.name = factor(trial.name))
sim_form <- bf(response ~ 0 + condition.name + (1 | participant.name + trial.name))
sim_prior <- c(brms::prior(normal(0.001, .3), class = "b"))
fit <- run_model_cmdstanr(sim_dataset,sim_form,"gaussian",sim_prior)
# 2. Simulation - Perform power analysis for different parameters
nParti <- c(5, 10, 11, 15, 20, 25, 30) # number participants
sdParti <- c(0.25) # sd participants
mDiff <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6) # for calculatingCohen's d
for (mDiff_loop in mDiff){ # test for different Cohen's d
for (sdParti_loop in sdParti){ # test different standard deviations for participants
for (nParti_loop in nParti){ # test different number of participants
for (loop in 1:5){ # 5 is for checking, use 500 in real test
print(paste("-->> n_participant=",nParti_loop, "-- loop", loop))
total = 2 * nParti_loop * 4
condition1 <- rnorm(total/2,mDiff_loop,1) %>% data.frame(condition.value = .)
condition2 <- rnorm(total/2,0,1) %>% data.frame(condition.value = .)
condition <- rbind(condition1,condition2)
cohend = mDiff_loop /sd(condition$condition.value)
# dit kan beter door elke participant ook conditioneel te maken tov conditie
participant <- rnorm(total,0,sdParti_loop) %>% data.frame(participant.value = .)
trial <- rnorm(total,0,0.1 ) %>% data.frame(trial.value = .)
gr_value <- cbind(condition,participant,trial) %>% data.frame()
gr_name <- expand_grid(c("c1","c2"),factor(c(1:nParti_loop)),factor(c(1:n_trial)))  %>% data.frame()
names(gr_name) <- c("condition.name","participant.name","trial.name")
gr <- cbind(gr_value,gr_name)
sim_dataset <- gr %>% mutate(response = condition.value + participant.value + trial.value)
sim_dataset <- sim_dataset %>% mutate(condition.name = factor(condition.name),
participant.name = factor(participant.name),
trial.name = factor(trial.name))
sim_model <-  update(fit,newdata = sim_dataset)
h <- hypothesis(sim_model,c("b_condition.namec1 > b_condition.namec2") ,class = NULL)$hypothesis
score <- ifelse(h[7] > 0.95,1,0) %>% data.frame()
names(score) ="score"
hh <- cbind(h,score)
print(paste("-------->> score = ", score,
"nParti =", nParti_loop,
"sdParti = ", sdParti_loop,
"mDiff = ",mDiff_loop,
"cohend = ", cohend))  #the real Dohen d
Score <- rbind(Score,cbind(hh, nParti_loop, sdParti_loop, mDiff_loop, cohend))
}
} # p_loop
} #sd_loop
} #d_loop
# Save simulation results along with additional information
nParti <- c(5, 10, 11, 15, 20, 25, 30) # number participants
sdParti <- c(0.25) # sd participants
mDiff <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6) # for calculatingCohen's d
Info <- list(Cohen_d = 0.5, nParti = nParti, sdParti = sdParti)
ScoreWithInfo = list(Score,Info)
save(file = "Fit/PowerAnalyse03_ScoreWithInfo",ScoreWithInfo)
Score <- ScoreWithInfo[[1]]
# Filter out unnecessary data
nParti <- c(5, 10, 11, 15, 20, 25, 30) # number participants
sdParti <- c(0.25) # sd participants
mDiff <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5) # for calculatingCohen's d
Info <- list(nParti = nParti, sdParti = sdParti, mDiff = mDiff)
ScoreWithInfo = list(Score,Info)
save(file = "Fit/PowerAnalyse03_ScoreWithInfo",ScoreWithInfo)
Score <- ScoreWithInfo[[1]]
Score <- ScoreWithInfo[[1]] %>% data.frame() %>% filter(!(nParti_loop == c(11)) )
# Analyze and visualize simulation results
Res0 <- Score %>% filter(!(nParti_loop == 11)) %>% group_by(nParti_loop,sdParti_loop,mDiff_loop) %>% summarize(s = mean(score))
# Create power analysis plots
po0 <- ggplot(Res0,aes(x=nParti_loop,y=s,color=factor(mDiff_loop)) ) +
geom_point(position = position_jitter(width=.1)) +
labs(color = "D") +
geom_line() +
geom_vline(xintercept = 11, linetype = 2, color = "red") +
xlab("Number of participants") +
ylab("Power") +
theme_bw() +
ggtitle("Power analysis")
po0
make_fig("FiguresPaper/PowerAnalysis03",po0)
po1 <- ggplot(Res0,aes(x=nParti_loop,y=s,color=factor(mDiff_loop))) +
# geom_point(position = position_jitter()) +
# stat_lineribbon() +
stat_summary(fun.y = mean, geom = "point") +
stat_summary(fun.data = mean_hdci, geom = "errorbar")+
geom_vline(xintercept = 11, linetype = 2, color = "red") +
xlab("Number of participants") +
ylab("Power c1 < c2") +
theme_bw() +
ggtitle("Power analysiss")
po1
po2 <- ggplot(Res0,aes(x=mDiff_loop,y=s,color=factor(nParti_loop))) +
geom_point(position = position_jitter(width = .01)) +
geom_line() +
#geom_vline(xintercept = 11, linetype = 2, color = "red") +
xlab("Cohen's d") +
ylab("Power c1 < c2") +
theme_bw() +
ggtitle("Power analysiss")
po2
knitr::opts_chunk$set(echo = TRUE)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
load(file = "Data.RData")
str(Data)
head(Data)
summary(Data)
load(file = "Data.RData")
library(ggplot2)
library(patchwork)
p1 <- ggplot(Data) +
geom_point(aes(x=participant,y=response0M_procustus, color = factor(condition)), position = position_jitterdodge()) +
ggtitle("procustus")
p2 <- ggplot(Data) +
geom_point(aes(x=participant,y=response1M_procustus, color = factor(condition)), position = position_jitterdodge()) +
ggtitle("procustus-calibrated")
p3 <- ggplot(Data) +
geom_point(aes(x=participant,y=response0M_sparc, color = factor(condition)), position = position_jitterdodge()) +
ggtitle("sparc")
p4 <- ggplot(Data) +
geom_point(aes(x=participant,y=response1M_sparc, color = factor(condition)), position = position_jitterdodge())+
ggtitle("sparc-calibrated")
p1 / p2
p3 / p4
load(file = "Data.RData")
library(ggplot2)
library(patchwork)
p5 <- ggplot(Data) +
geom_point(aes(x=participant,y=WPQ, color = factor(condition)), position = position_jitterdodge())+
ggtitle("Witmer Presence questionnaire")
p6 <- ggplot(Data) +
geom_point(aes(x=participant,y=MPQS, color = factor(condition)), position = position_jitterdodge())+
ggtitle("social Makransky multimodal presence scale")
p7 <- ggplot(Data) +
geom_point(aes(x=participant,y=MPQP, color = factor(condition)), position = position_jitterdodge())+
ggtitle("physical Makransky multimodal presence scale")
p8 <- ggplot(Data) +
geom_point(aes(x=participant,y=difficulty_s, color = factor(condition)), position = position_jitterdodge())+
ggtitle("Perceived difficulty")
p5 / p6
p7 / p8
load(file = "Results/BF_model_comparison_procustus0M.RData")
load(file = "Results/BF_model_comparison_sparc0M.RData")
print(paste("Bayes factor in favor of model_1 over model_2 (procutus0M): ", BF_model_comparison_procustus0M$bf ))
print(paste("Bayes factor in favor of model_1 over model_2 (sparc0M): ", BF_model_comparison_sparc0M$bf ))
load(file = "Results/BF_model_comparison_procustus1M.RData")
load(file = "Results/BF_model_comparison_sparc1M.RData")
print(paste("Bayes factor in favor of model_1 over model_2 (procustus1M): ", BF_model_comparison_procustus1M$bf ))
print(paste("Bayes factor in favor of model_1 over model_2 (sparc1M): ", BF_model_comparison_sparc1M$bf ))
load(file = "Results/post_analysis_procustus0M.RData")
load(file = "Results/post_analysis_sparc0M.RData")
post_analysis_procustus0M
post_analysis_sparc0M
load(file = "Results/post_analysis_procustus1M.RData")
load(file = "Results/post_analysis_sparc1M.RData")
post_analysis_procustus1M
post_analysis_sparc1M
load(file = "Results/hypothesis_test_procustus0M.RData")
load(file = "Results/hypothesis_test_sparc0M.RData")
hypothesis_test_procustus0M[[1]][,1]
hypothesis_test_procustus0M[[1]][,-1]
hypothesis_test_procustus0M[[2]]
hypothesis_test_sparc0M[[1]][,1]
hypothesis_test_sparc0M[[1]][,-1]
hypothesis_test_sparc0M[[2]]
load(file = "Results/hypothesis_test_procustus1M.RData")
load(file = "Results/hypothesis_test_sparc1M.RData")
hypothesis_test_procustus1M[[1]][,1]
hypothesis_test_procustus1M[[1]][,-1]
hypothesis_test_procustus1M[[2]]
hypothesis_test_sparc1M[[1]][,1]
hypothesis_test_sparc1M[[1]][,-1]
hypothesis_test_sparc1M[[2]]
load(file = "Results/BF_model_comparison_WPQ_0M.RData")
load(file = "Results/BF_model_comparison_MPQS_0M.RData")
load(file = "Results/BF_model_comparison_MPQP_0M.RData")
load(file = "Results/BF_model_comparison_Difficulty_0M.RData")
print(paste("Bayes factor in favor of model_3 over model_4 (WPQ_0M): ", BF_model_comparison_WPQ_0M ))
print(paste("Bayes factor in favor of model_3 over model_4 (MPQS_0M): ", BF_model_comparison_MPQS_0M ))
print(paste("Bayes factor in favor of model_3 over model_4 (MPQP_0M): ", BF_model_comparison_MPQP_0M ))
print(paste("Bayes factor in favor of model_3 over model_4 (Difficulty_OM): ", BF_model_comparison_Difficulty_0M ))
load(file = "Results/BF_model_comparison_WPQ_1M.RData")
load(file = "Results/BF_model_comparison_MPQS_1M.RData")
load(file = "Results/BF_model_comparison_MPQP_1M.RData")
load(file = "Results/BF_model_comparison_Difficulty_1M.RData")
print(paste("Bayes factor in favor of model_3 over model_4 (WPQ_1M): ", BF_model_comparison_WPQ_1M ))
print(paste("Bayes factor in favor of model_3 over model_4 (MPQS_1M): ", BF_model_comparison_MPQS_1M ))
print(paste("Bayes factor in favor of model_3 over model_4 (MPQP_1M): ", BF_model_comparison_MPQP_1M ))
print(paste("Bayes factor in favor of model_3 over model_4 (Difficulty_1M): ", BF_model_comparison_Difficulty_1M ))
load(file = "Results/post_analysis_procustus_basicWPQ.RData")
load(file = "Results/post_analysis_procustus_basicMPQS.RData")
load(file = "Results/post_analysis_procustus_basicMPQP.RData")
load(file = "Results/post_analysis_procustus_basicDifficulty.RData")
post_analysis_procustus_basicWPQ
post_analysis_procustus_basicMPQS
post_analysis_procustus_basicMPQP
post_analysis_procustus_basicDifficulty
load(file = "Results/Contrast_WPQ.RData")
load(file = "Results/Contrast_MPQS.RData")
load(file = "Results/Contrast_MPQP.RData")
load(file = "Results/Contrast_Difficulty.RData")
Contrasts_Questionnaires <- rbind(
Contrast_WPQ[[1]][-1],
Contrast_MPQS[[1]][-1],
Contrast_WPQP[[1]][-1],
Contrast_Difficulty[[1]][-1]
)
rownames(Contrasts_Questionnaires) <- NULL
Contrasts_Questionnaires
